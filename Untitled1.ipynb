{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0f5440-0e46-45e5-8ba8-b19dcddbead3",
   "metadata": {},
   "source": [
    "##### Scraper Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cb3900-ce0e-45bc-9415-5353f8746055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43a417-51e4-498a-b2e3-a51e1787d5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e4b840-e0c1-44de-bc4f-f68f391049e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (2942581399.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    articles_data = pd.read_csv(\"\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "#Reading in dataset\n",
    "articles_data = pd.read_csv(\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cf2980d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3492303363.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    18 Years Old\tNo\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "18 Years Old\tNo\n",
    "2\tTunisia\t36.6 L\t0.2%\t18 Years Old\tNo\n",
    "3\tEswatini\t34.4 L\t2.5%\t18 Years Old\tNo\n",
    "4\tMaldives\t33.7 L\t0.9%\t\tYes\n",
    "5\tAfghanistan\t33.5 L\t0.2%\t\tYes\n",
    "6\tNamibia\t32.4 L\t2.2%\t18 Years Old\tNo\n",
    "7\tSouth Africa\t29.9 L\t2.4%\t18 Years Old\tNo\n",
    "8\tAlgeria\t29.1 L\t0.7%\t18 Years Old\tNo\n",
    "9\tTurkey\t28.5 L\t1.6%\t18 Years Old\tNo\n",
    "10\tIran\t28.4 L\t0.6%\t\tYes\n",
    "11\tLesotho\t28.2 L\t1.8%\t21 Years Old\tNo\n",
    "12\tGeorgia\t27.9 L\t2.1%\t16 Years Old\tNo\n",
    "13\tNauru\t27.3 L\t3%\t21 Years Old\tNo\n",
    "14\tLibya\t26.4 L\t0.2%\t\tYes\n",
    "15\tBotswana\t26.2 L\t2.5%\t18 Years Old\tNo\n",
    "16\tPakistan\t26 L\t0.2%\t\tYes\n",
    "17\tUganda\t26 L\t2.5%\t18 Years Old\tNo\n",
    "18\tLaos\t25.9 L\t2.8%\t\t\n",
    "19\tTanzania\t25.8 L\t2.4%\t18 Years Old\tNo\n",
    "20\tRwanda\t25.6 L\t2.5%\t18 Years Old\tNo\n",
    "21\tNigeria\t25.5 L\t0.1%\t18 Years Old\tNo\n",
    "22\tLebanon\t25 L\t3.7%\t18 Years Old\tNo\n",
    "23\tJordan\t24.6 L\t0.2%\t18 Years Old\tNo\n",
    "24\tMorocco\t24.5 L\t0.2%\t18 Years Old\tNo\n",
    "25\tKyrgyzstan\t24 L\t3.3%\t18 Years Old\tNo\n",
    "26\tBurundi\t23.7 L\t2.4%\t16 Years Old\tNo\n",
    "27\tMoldova\t22.8 L\t3.3%\t18 Years Old\tNo\n",
    "28\tVietnam\t22.8 L\t2.9%\t18 Years Old\tNo\n",
    "29\tCameroon\t22.6 L\t2.5%\t21 Years Old\tNo\n",
    "30\tComoros\t22.3 L\t0.7%\t18 Years Old\tNo\n",
    "31\tBurkina Faso\t22.2 L\t0.7%\t\tNo\n",
    "32\tBahrain\t22.1 L\t0.3%\t21 Years Old\tNo\n",
    "33\tSudan\t22 L\t0.2%\t\tYes\n",
    "34\tMongolia\t21.9 L\t2.8%\t18 Years Old\tNo\n",
    "35\tSeychelles\t21.8 L\t2.5%\t18 Years Old\tNo\n",
    "36\tCambodia\t21.7 L\t2.7%\t21 Years Old\tNo\n",
    "37\tIvory Coast\t21.7 L\t\t18 Years Old\tNo\n",
    "38\tArmenia\t21.3 L\t3.2%\t18 Years Old\tNo\n",
    "39\tUnited Arab Emirates\t20.5 L\t0.3%\t21 Years Old\tNo\n",
    "40\tThailand\t20.3 L\t1.8%\t20 Years Old\tNo\n",
    "41\tParaguay\t20.1 L\t2.9%\t20 Years Old\tNo\n",
    "42\tRussia\t20.1 L\t9.3%\t18 Years Old\tNo\n",
    "43\tSão Tomé and Príncipe\t20.1 L\t2.2%\t18 Years Old\tNo\n",
    "44\tPhilippines\t19.9 L\t2.9%\t18 Years Old\tNo\n",
    "45\tSaint Lucia\t19.8 L\t2.8%\t16 Years Old\tNo\n",
    "46\tBrazil\t19.3 L\t1.4%\t18 Years Old\tNo\n",
    "47\tBulgaria\t19.2 L\t2.3%\t18 Years Old\tNo\n",
    "48\tKazakhstan\t19.2 L\t3.3%\t21 Years Old\tNo\n",
    "49\tCzech Republic\t19.1 L\t2.8%\t18 Years Old\tNo\n",
    "50\tBarbados\t19 L\t2.7%\t16 Years Old\tNo\n",
    "51\tLithuania\t18.9 L\t4.9%\t18 Years Old\tNo\n",
    "52\tRomania\t18.8 L\t1.3%\t18 Years Old\tNo\n",
    "53\tGrenada\t18.7 L\t2.8%\t18 Years Old\tNo\n",
    "54\tLiberia\t18.7 L\t1.8%\t18 Years Old\tNo\n",
    "55\tSerbia\t18.5 L\t3.4%\t18 Years Old\tNo\n",
    "56\tSierra Leone\t18.3 L\t0.7%\t18 Years Old\tNo\n",
    "57\tDominica\t18 L\t2.8%\t16 Years Old\tNo\n",
    "58\tPortugal\t17.8 L\t3%\t18 Years Old\tNo\n",
    "59\tTurkmenistan\t17.8 L\t3.3%\t18 Years Old\tNo\n",
    "60\tSaint Vincent and the Grenadines\t17.7 L\t2.8%\t18 Years Old\tNo\n",
    "61\tSlovenia\t17.7 L\t6.2%\t18 Years Old\tNo\n",
    "62\tZambia\t17.7 L\t1.9%\t18 Years Old\tNo\n",
    "63\tMyanmar\t17.6 L\t0.7%\t18 Years Old\tNo\n",
    "64\tGabon\t17.2 L\t2.4%\t18 Years Old\tNo\n",
    "65\tLatvia\t17.2 L\t10.4%\t18 Years Old\tNo\n",
    "66\tHungary\t17.1 L\t9.4%\t18 Years Old\tNo\n",
    "67\tPoland\t17.1 L\t2.2%\t18 Years Old\tNo\n",
    "68\tSaint Kitts and Nevis\t17.1 L\t2.8%\t18 Years Old\tNo\n",
    "69\tFiji\t16.9 L\t3%\t18 Years Old\tNo\n",
    "70\tGermany\t16.9 L\t3.5%\t16 Years Old\tNo\n",
    "71\tFrance\t16.7 L\t3.3%\t18 Years Old\tNo\n",
    "72\tSlovakia\t16.6 L\t5.5%\t18 Years Old\tNo\n",
    "73\tGuinea-Bissau\t16.5 L\t0.7%\t\tNo\n",
    "74\tHaiti\t16.5 L\t2.8%\t16 Years Old\tNo\n",
    "\n",
    "ages = re.findall(r'\\b\\d+\\s*Years?\\s*Old\\b', data)\n",
    "\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4c5f81",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Downloads/alcohol_consumption_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Read data from a file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloads/alcohol_consumption_data.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Regular expression pattern to match percentage values\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Downloads/alcohol_consumption_data.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read data from a file\n",
    "with open(\"Downloads/alcohol_consumption_data.txt\", \"r\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Regular expression pattern to match percentage values\n",
    "pattern = r'(\\d+(\\.\\d+)?%)'\n",
    "\n",
    "# Find all percentage values in the data\n",
    "percentages = re.findall(pattern, data)\n",
    "\n",
    "# Extract the percentage values from the tuples\n",
    "percentages = [match[0] for match in percentages]\n",
    "\n",
    "# Print the extracted percentage values\n",
    "for percentage in percentages:\n",
    "    print(percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b54d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(\"/Users/nick/Downloads/Alcohol Consumption Data .txt\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Open the file\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = file.read()\n",
    "else:\n",
    "    print(\"File not found:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b065976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found at path: /Users/nick/Downloads/alcohol_consumption_data.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Specify the absolute path to the file\n",
    "file_path = \"/Users/nick/Downloads/alcohol_consumption_data.txt\"\n",
    "\n",
    "# Read data from the file\n",
    "try:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = file.read()\n",
    "    # Continue with further processing\n",
    "    print(\"File successfully read.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c882b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2%\n",
      "0.2%\n",
      "2.5%\n",
      "0.9%\n",
      "0.2%\n",
      "2.2%\n",
      "2.4%\n",
      "0.7%\n",
      "1.6%\n",
      "0.6%\n",
      "1.8%\n",
      "2.1%\n",
      "0.2%\n",
      "2.5%\n",
      "0.2%\n",
      "2.5%\n",
      "2.8%\n",
      "2.4%\n",
      "2.5%\n",
      "0.1%\n",
      "3.7%\n",
      "0.2%\n",
      "0.2%\n",
      "3.3%\n",
      "2.4%\n",
      "3.3%\n",
      "2.9%\n",
      "2.5%\n",
      "0.7%\n",
      "0.7%\n",
      "0.3%\n",
      "0.2%\n",
      "2.8%\n",
      "2.5%\n",
      "2.7%\n",
      "3.2%\n",
      "0.3%\n",
      "1.8%\n",
      "2.9%\n",
      "9.3%\n",
      "2.2%\n",
      "2.9%\n",
      "2.8%\n",
      "1.4%\n",
      "2.3%\n",
      "3.3%\n",
      "2.8%\n",
      "2.7%\n",
      "4.9%\n",
      "1.3%\n",
      "2.8%\n",
      "1.8%\n",
      "3.4%\n",
      "0.7%\n",
      "2.8%\n",
      "3.3%\n",
      "2.8%\n",
      "6.2%\n",
      "1.9%\n",
      "0.7%\n",
      "2.4%\n",
      "10.4%\n",
      "9.4%\n",
      "2.2%\n",
      "2.8%\n",
      "3.5%\n",
      "3.3%\n",
      "5.5%\n",
      "0.7%\n",
      "2.8%\n",
      "2.8%\n",
      "3.1%\n",
      "2.8%\n",
      "2.9%\n",
      "2.8%\n",
      "3.8%\n",
      "5.5%\n",
      "4.3%\n",
      "5.5%\n",
      "2.7%\n",
      "2.8%\n",
      "0.4%\n",
      "2.7%\n",
      "3.1%\n",
      "2.4%\n",
      "1.2%\n",
      "0.2%\n",
      "1.3%\n",
      "3.2%\n",
      "3.4%\n",
      "3.4%\n",
      "0.7%\n",
      "3.4%\n",
      "5.8%\n",
      "2.6%\n",
      "2.8%\n",
      "4.5%\n",
      "3.4%\n",
      "3.4%\n",
      "2.9%\n",
      "3.8%\n",
      "0.7%\n",
      "0.6%\n",
      "1.3%\n",
      "2.7%\n",
      "4.3%\n",
      "2.8%\n",
      "1.1%\n",
      "1.4%\n",
      "2.9%\n",
      "0.7%\n",
      "3.9%\n",
      "4.1%\n",
      "2.2%\n",
      "2.5%\n",
      "7.7%\n",
      "2.9%\n",
      "2.1%\n",
      "1.5%\n",
      "3.4%\n",
      "2.7%\n",
      "2.3%\n",
      "2.7%\n",
      "1.9%\n",
      "1.6%\n",
      "3.3%\n",
      "0.8%\n",
      "0.2%\n",
      "2.8%\n",
      "0.6%\n",
      "0.6%\n",
      "3.3%\n",
      "1.5%\n",
      "4.9%\n",
      "2.2%\n",
      "1.9%\n",
      "1.1%\n",
      "2.9%\n",
      "2.9%\n",
      "1.4%\n",
      "2.8%\n",
      "1.4%\n",
      "0.7%\n",
      "2.8%\n",
      "0.9%\n",
      "0.3%\n",
      "2.8%\n",
      "1.3%\n",
      "2.9%\n",
      "0.7%\n",
      "2.9%\n",
      "1.7%\n",
      "3.3%\n",
      "0.7%\n",
      "0.8%\n",
      "0.7%\n",
      "0.7%\n",
      "0.1%\n",
      "0.2%\n",
      "0.2%\n",
      "3.4%\n",
      "0.7%\n",
      "0.7%\n",
      "1.1%\n",
      "0.5%\n",
      "0.2%\n",
      "0.7%\n",
      "0.8%\n",
      "0.2%\n",
      "0.8%\n",
      "0.2%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"/Users/nick/Downloads/Alcohol Consumption Data .txt\"\n",
    "\n",
    "# Read data from the file using open() function\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Regular expression pattern to match percentage values\n",
    "pattern = r'\\d+\\.\\d+%'\n",
    "\n",
    "# Find all matches in the data\n",
    "matches = re.findall(pattern, data)\n",
    "\n",
    "# Print the percentage values\n",
    "for match in matches:\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4812b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db92dc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nick'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1994a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/nick/Downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7546fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a0f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635e8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” - Albert Einstein\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.” - J.K. Rowling\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” - Albert Einstein\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” - Jane Austen\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” - Marilyn Monroe\n",
      "“Try not to become a man of success. Rather become a man of value.” - Albert Einstein\n",
      "“It is better to be hated for what you are than to be loved for what you are not.” - André Gide\n",
      "“I have not failed. I've just found 10,000 ways that won't work.” - Thomas A. Edison\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.” - Eleanor Roosevelt\n",
      "“A day without sunshine is like, you know, night.” - Steve Martin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:228: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "page_to_scrape = requests.get(\"https://quotes.toscrape.com\", headers={\"Accept-Encoding\": \"utf-8\"}) \n",
    "soup = BeautifulSoup(page_to_scrape.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "quotes = soup.findAll(\"span\", attrs={\"class\":\"text\"})\n",
    "authors = soup.findAll(\"small\", attrs={\"class\":\"author\"})\n",
    "\n",
    "file = open(\"scraped_quotes.csv\", \"w\")\n",
    "writer = csv.writer(file)\n",
    "\n",
    "writer.writerow([\"QUOTES\", \"AUTHORS\"])\n",
    "\n",
    "for quote, author in zip(quotes, authors):\n",
    "    print (quote.text + \" - \"+ author.text)\n",
    "    writer.writerow([quote.text, author.text])\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6028e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"http://quotes.toscrape.com\")\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all quotes and authors\n",
    "quotes = soup.find_all(\"span\", class_=\"text\")\n",
    "authors = soup.find_all(\"small\", class_=\"author\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_quotes2.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writerow([\"QUOTES\", \"AUTHORS\"])\n",
    "\n",
    "    # Iterate over quotes and authors, write to CSV\n",
    "    for quote, author in zip(quotes, authors):\n",
    "        writer.writerow([quote.get_text(), author.get_text()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f914888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"http://quotes.toscrape.com\")\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all quotes and authors\n",
    "quotes = soup.find_all(\"span\", class_=\"text\")\n",
    "authors = soup.find_all(\"small\", class_=\"author\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_quotes3.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writerow([\"QUOTES\", \"AUTHORS\"])\n",
    "\n",
    "    # Iterate over quotes and authors, write to CSV\n",
    "    for quote, author in zip(quotes, authors):\n",
    "        writer.writerow([quote.get_text(), author.get_text()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6d8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import html\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"http://quotes.toscrape.com\")\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all quotes and authors\n",
    "quotes = soup.find_all(\"span\", class_=\"text\")\n",
    "authors = soup.find_all(\"small\", class_=\"author\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_quotes.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writerow([\"QUOTES\", \"AUTHORS\"])\n",
    "\n",
    "    # Iterate over quotes and authors, write to CSV\n",
    "    for quote, author in zip(quotes, authors):\n",
    "        # Convert HTML entities to Unicode characters\n",
    "        cleaned_quote = html.unescape(quote.get_text())\n",
    "        cleaned_author = html.unescape(author.get_text())\n",
    "        writer.writerow([cleaned_quote, cleaned_author])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a201f743",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m page_to_scrape \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://quotes.toscrape.com\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Parse the HTML content using html5lib parser\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page_to_scrape\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml5lib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Find all quotes and authors\u001b[39;00m\n\u001b[1;32m     12\u001b[0m quotes \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"https://wisevoter.com/country-rankings/alcohol-consumption-by-country/\")\n",
    "\n",
    "# Parse the HTML content using html5lib parser\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html5lib\")\n",
    "\n",
    "# Find all quotes and authors\n",
    "quotes = soup.find_all(\"span\", class_=\"text\")\n",
    "authors = soup.find_all(\"small\", class_=\"author\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_quotes2.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writerow([\"QUOTES\", \"AUTHORS\"])\n",
    "\n",
    "    # Iterate over quotes and authors, write to CSV\n",
    "    for quote, author in zip(quotes, authors):\n",
    "        writer.writerow([quote.get_text(), author.get_text()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e768ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Obtaining dependency information for html5lib from https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: six>=1.9 in ./anaconda3/lib/python3.11/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./anaconda3/lib/python3.11/site-packages (from html5lib) (0.5.1)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m450.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install html5lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7c2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/nick/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - html5lib\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.3.11  |       hca03da5_0         128 KB\n",
      "    certifi-2024.2.2           |  py311hca03da5_0         161 KB\n",
      "    html5lib-1.1               |     pyhd3eb1b0_0          91 KB\n",
      "    openssl-3.0.13             |       h1a28f6b_0         5.0 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  html5lib           pkgs/main/noarch::html5lib-1.1-pyhd3eb1b0_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2023.08.22-hca03da5_0 --> 2024.3.11-hca03da5_0 \n",
      "  certifi                        2023.11.17-py311hca03da5_0 --> 2024.2.2-py311hca03da5_0 \n",
      "  openssl                                 3.0.12-h1a28f6b_0 --> 3.0.13-h1a28f6b_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-3.0.13       | 5.0 MB    |                                       |   0% \n",
      "ca-certificates-2024 | 128 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "certifi-2024.2.2     | 161 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "html5lib-1.1         | 91 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "certifi-2024.2.2     | 161 KB    | ###6                                  |  10% \u001b[A\u001b[A\n",
      "ca-certificates-2024 | 128 KB    | ####6                                 |  12% \u001b[A\n",
      "\n",
      "\n",
      "html5lib-1.1         | 91 KB     | ######5                               |  18% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "html5lib-1.1         | 91 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "openssl-3.0.13       | 5.0 MB    | 1                                     |   0% \u001b[A\n",
      "\n",
      "\n",
      "html5lib-1.1         | 91 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.13       | 5.0 MB    | 9                                     |   2% \u001b[A\u001b[A\n",
      "ca-certificates-2024 | 128 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install html5lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df737ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"https://wisevoter.com/country-rankings/alcohol-consumption-by-country/\")\n",
    "\n",
    "# Parse the HTML content using lxml parser\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all <td> elements with class \"shdb-on-page-table-body-Geo\" (country names)\n",
    "countries = soup.findAll(\"td\", class_=\"shdb-on-page-table-body-Geo\")\n",
    "\n",
    "# Find all <td> elements with class \"shdb-on-page-table-body-Y2\" (alcohol consumption per capita)\n",
    "consumptions = soup.findAll(\"td\", class_=\"shdb-on-page-table-body-Y2\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_alcohol_consumption.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writerow([\"COUNTRY\", \"ALCOHOL CONSUMPTION (per capita)\"])\n",
    "\n",
    "    # Iterate over countries and corresponding alcohol consumptions, write to CSV\n",
    "    for country, consumption in zip(countries, consumptions):\n",
    "        country_name = country.text.strip()  # Extract text content of country and strip whitespace\n",
    "        alcohol_consumption = consumption.text.strip()  # Extract text content of consumption and strip whitespace\n",
    "        writer.writerow([country_name, alcohol_consumption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e80daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"https://wisevoter.com/country-rankings/alcohol-consumption-by-country/\")\n",
    "\n",
    "# Parse the HTML content using lxml parser\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_alcohol_consumption2.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writerow([\"COUNTRY\", \"ALCOHOL CONSUMPTION (per capita)\"])\n",
    "\n",
    "    # Iterate over rows, excluding the header row\n",
    "    for row in rows[1:]:\n",
    "        # Find country name and alcohol consumption per capita in each row\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) >= 2:  # Ensure there are at least two columns\n",
    "            country_name = columns[0].get_text(strip=True)\n",
    "            alcohol_consumption = columns[1].get_text(strip=True)\n",
    "            writer.writerow([country_name, alcohol_consumption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a724e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"https://wisevoter.com/country-rankings/alcohol-consumption-by-country/\")\n",
    "\n",
    "# Parse the HTML content using lxml parser\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_alcohol_consumption3.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writerow([\"COUNTRY\", \"ALCOHOL CONSUMPTION (per capita)\"])\n",
    "\n",
    "    # Iterate over rows, excluding the header row\n",
    "    for row in rows[1:]:\n",
    "        # Find country name and alcohol consumption per capita in each row\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) >= 2:  # Ensure there are at least two columns\n",
    "            country_name = columns[1].get_text(strip=True)  # Country name is in the second column\n",
    "            alcohol_consumption = columns[2].get_text(strip=True)  # Alcohol consumption per capita is in the third column\n",
    "            writer.writerow([country_name, alcohol_consumption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cd0ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"https://wisevoter.com/country-rankings/alcohol-consumption-by-country/\")\n",
    "\n",
    "# Parse the HTML content using lxml parser\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_alcohol_consumption.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    headers = [th.get_text(strip=True) for th in rows[0].find_all(\"th\")]\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Iterate over rows, excluding the header row\n",
    "    for row in rows[1:]:\n",
    "        # Find data in each row\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) >= 5:  # Ensure there are at least five columns (including country name and alcohol consumption per capita)\n",
    "            # Extract data from each column\n",
    "            country = columns[1].get_text(strip=True)\n",
    "            beer = columns[2].get_text(strip=True)\n",
    "            wine = columns[3].get_text(strip=True)\n",
    "            spirits = columns[4].get_text(strip=True)\n",
    "            total_litres = columns[5].get_text(strip=True)\n",
    "\n",
    "            # Write data to CSV file\n",
    "            writer.writerow([country, beer, wine, spirits, total_litres])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75292d38",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3813886329.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    writer = csv.writer(file\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"https://wisevoter.com/country-rankings/alcohol-consumption-by-country/\")\n",
    "\n",
    "# Parse the HTML content using lxml parser\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_alcohol_consumption2.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffded9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send GET request\n",
    "page_to_scrape = requests.get(\"https://wisevoter.com/country-rankings/alcohol-consumption-by-country/\")\n",
    "\n",
    "# Parse the HTML content using lxml parser\n",
    "soup = BeautifulSoup(page_to_scrape.content, \"html.parser\")\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = soup.find_all(\"tr\")\n",
    "\n",
    "# Open CSV file in write mode with utf-8 encoding\n",
    "with open(\"scraped_alcohol_consumption5.csv\", \"w\", newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers\n",
    "    headers = [\"COUNTRY\", \"Alcohol Consumption Per Capita\", \"Prevalence of Alcohol Dependence\", \n",
    "               \"Legal Drinking Age\", \"Alcohol Illegality\"]\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Iterate over rows, excluding the header row\n",
    "    for row in rows[1:]:\n",
    "        # Find data in each row\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) >= 6:  # Ensure there are at least six columns (including #, Country, Beer, Wine, Spirits, Total litres)\n",
    "            # Extract data from each column\n",
    "            country = columns[1].get_text(strip=True)\n",
    "            Alcohol_Consumption_Per_Capita = columns[2].get_text(strip=True)\n",
    "            Prevalence_of_Alcohol_Dependence = columns[3].get_text(strip=True)\n",
    "            Legal_Drinking_Age = columns[4].get_text(strip=True)\n",
    "            Alcohol_Illegality = columns[5].get_text(strip=True)\n",
    "\n",
    "            # Write data to CSV file\n",
    "            writer.writerow([country, beer, wine, spirits, total_litres])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9390443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b4b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ee0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
